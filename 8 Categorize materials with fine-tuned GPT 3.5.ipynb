{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcf02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "152e94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from langchain.vectorstores import Chroma\n",
    "import json\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AdamW\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import HTML, display\n",
    "import getpass\n",
    "import logging\n",
    "import os\n",
    "import yaml\n",
    "from datasets import load_dataset\n",
    "import numpy as np; np.random.seed(123)\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML, display\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4cf82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158173"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8431c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt= pd.read_csv('Categorization dataset.csv')\n",
    "gt.head()\n",
    "len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fde2888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_c = []\n",
    "for _, (Material_Name, Caption, DOI, Descriptor, Category) in gt.iterrows():\n",
    "    Prompt = f\"\"\"How do you categorize the material called '{Material_Name}' based on the following information: \n",
    "    Caption of the table that described the chemical composition of this material: {Caption}\n",
    "    Descriptor from another language model: {Descriptor}\n",
    "    \n",
    "    Category of the material '{Material_Name}': \"\"\"\n",
    "\n",
    "    dataset_c.append({\"Prompt\": Prompt, \"Winner\": str(Category)})\n",
    "    \n",
    "len(dataset_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53c8a271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Material Name                                                   FA\n",
       "Caption          Major elements present in the S/S agents and M...\n",
       "DOI                                  10.1016/j.jhazmat.2010.08.127\n",
       "Descriptor        Class F fly ash, specifically low calcium fly...\n",
       "Category          Ash, Fly, Class F, Byproduct of coal combustion \n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "069b03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_dataset=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb10ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformatting for fine-tuning\n",
    "fine_tuning_dataset = []\n",
    "for item in dataset_c:\n",
    "    fine_tuning_item = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant trained to classify the materials based on the description provided and your own knowledge about materials. \"},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(item[\"Prompt\"])},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(item[\"Winner\"])}\n",
    "        ]\n",
    "    }\n",
    "    fine_tuning_dataset.append(fine_tuning_item)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a5bdeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fine_tuning_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "208bd34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are an assistant trained to classify the materials based on the description provided and your own knowledge about materials. Consider these keywords and abbreviations that are used in concrete industry to classify the materials: {cheat_sheet}'},\n",
       "  {'role': 'user',\n",
       "   'content': '\"How do you categorize the material called \\'FA\\' based on the following information: \\\\n    Caption of the table that described the chemical composition of this material: Major elements present in the S/S agents and MSWI waste.\\\\n    Descriptor from another language model:  Class F fly ash, specifically low calcium fly ash from coal combustion, is used as the main aluminosilicate agent and geopolymer precursor in this study.\\\\n    \\\\n    Category of the material \\'FA\\': \"'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '\"Ash, Fly, Class F, Byproduct of coal combustion \"'}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8db8f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(fine_tuning_dataset, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fb89457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('fine_tuning_TE_ENR.jsonl', 'w') as file:\n",
    "    for item in fine_tuning_dataset:\n",
    "        json.dump(item, file)\n",
    "        file.write('\\n')\n",
    "        \n",
    "\n",
    "with open('fine_tuning_TRAIN_TE_ENR.jsonl', 'w') as file:\n",
    "    for item in train_data:\n",
    "        json.dump(item, file)\n",
    "        file.write('\\n')\n",
    "        \n",
    "\n",
    "with open('fine_tuning_TEST_TE_ENR.jsonl', 'w') as file:\n",
    "    for item in test_data:\n",
    "        json.dump(item, file)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9089fc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb9f720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"object\": \"file\",\r\n",
      "  \"id\": \"file-n57msb21C1844BMySxGKKeNL\",\r\n",
      "  \"purpose\": \"fine-tune\",\r\n",
      "  \"filename\": \"fine_tuning_TRAIN_TE_ENR.jsonl\",\r\n",
      "  \"bytes\": 281170,\r\n",
      "  \"created_at\": 1706208998,\r\n",
      "  \"status\": \"processed\",\r\n",
      "  \"status_details\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!curl https://api.openai.com/v1/files \\\n",
    "  -H \"Authorization: Bearer api_key\" \\\n",
    "  -F \"purpose=fine-tune\" \\\n",
    "  -F \"file=@fine_tuning_TRAIN_TE_ENR.jsonl\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06267805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"object\": \"file\",\r\n",
      "  \"id\": \"file-6jvYmnyirwy4K9Rm6Ay9SZ0U\",\r\n",
      "  \"purpose\": \"fine-tune\",\r\n",
      "  \"filename\": \"fine_tuning_TEST_TE_ENR.jsonl\",\r\n",
      "  \"bytes\": 24570,\r\n",
      "  \"created_at\": 1706209054,\r\n",
      "  \"status\": \"processed\",\r\n",
      "  \"status_details\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!curl https://api.openai.com/v1/files \\\n",
    "  -H \"Authorization: Bearer api_key\" \\\n",
    "  -F \"purpose=fine-tune\" \\\n",
    "  -F \"file=@fine_tuning_TEST_TE_ENR.jsonl\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38881a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-QPd8qCJe8ailytd99bJY7EdU', created_at=1706209099, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-CGIKMf8W0RLVflPNXCgE6SzT', result_files=[], status='validating_files', trained_tokens=None, training_file='file-n57msb21C1844BMySxGKKeNL', validation_file='file-6jvYmnyirwy4K9Rm6Ay9SZ0U')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-n57msb21C1844BMySxGKKeNL\", \n",
    "  validation_file=\"file-6jvYmnyirwy4K9Rm6Ay9SZ0U\", \n",
    "  model=\"gpt-3.5-turbo-1106\", \n",
    "  hyperparameters={\n",
    "    \"n_epochs\":\"auto\"\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1a48bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_responses(responses):\n",
    "    # Implement the logic to save 'responses'\n",
    "    # For example, saving to a file:\n",
    "    filename = f'responses_some.csv'\n",
    "    # Convert responses to DataFrame and save as CSV\n",
    "    pd.DataFrame(responses, columns=['Material Name','Caption','DOI','Descriptor','Response']).to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9602f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c15849f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9286d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material Name</th>\n",
       "      <th>SiO2</th>\n",
       "      <th>Al2O3</th>\n",
       "      <th>Fe2O3</th>\n",
       "      <th>CaO</th>\n",
       "      <th>MgO</th>\n",
       "      <th>SO3</th>\n",
       "      <th>TiO2</th>\n",
       "      <th>MnO</th>\n",
       "      <th>K2O</th>\n",
       "      <th>Na2O</th>\n",
       "      <th>LOI</th>\n",
       "      <th>Caption</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Descriptor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zeolitic rock from Sakhaptinskoje deposit</td>\n",
       "      <td>64.8</td>\n",
       "      <td>12.77</td>\n",
       "      <td>2.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.12</td>\n",
       "      <td>Chemical composition of primary material.</td>\n",
       "      <td>10.1016/j.conbuildmat.2009.10.010</td>\n",
       "      <td>The Zeolitic rock from Sakhaptinskoe deposit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ash microspheres</td>\n",
       "      <td>62.3</td>\n",
       "      <td>23.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Chemical composition of primary material.</td>\n",
       "      <td>10.1016/j.conbuildmat.2009.10.010</td>\n",
       "      <td>Ash microspheres are spherical particles prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vermiculite</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chemical composition of primary material.</td>\n",
       "      <td>10.1016/j.conbuildmat.2009.10.010</td>\n",
       "      <td>Vermiculite is a mineral composed primarily o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAC</td>\n",
       "      <td>0.2</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Oxide composition and chemical properties of H...</td>\n",
       "      <td>10.1016/j.conbuildmat.2010.01.022</td>\n",
       "      <td>The material named 'HAC' contains approximate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPC</td>\n",
       "      <td>22.1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>63.8</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Oxide composition and chemical properties of H...</td>\n",
       "      <td>10.1016/j.conbuildmat.2010.01.022</td>\n",
       "      <td>The material named 'OPC' has an oxide composi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Material Name  SiO2  Al2O3  Fe2O3   CaO    MgO  \\\n",
       "0  Zeolitic rock from Sakhaptinskoje deposit  64.8  12.77   2.46   NaN   1.84   \n",
       "1                           Ash microspheres  62.3  23.40   4.00   NaN   4.21   \n",
       "2                                Vermiculite  34.0  12.00   6.00   NaN  13.00   \n",
       "3                                        HAC   0.2  71.00   0.10  28.5   0.40   \n",
       "4                                        OPC  22.1   5.00   3.00  63.8   1.60   \n",
       "\n",
       "   SO3  TiO2  MnO   K2O  Na2O    LOI  \\\n",
       "0  NaN  0.35  NaN   NaN   NaN  11.12   \n",
       "1  NaN   1.3  NaN   NaN   NaN   1.74   \n",
       "2  NaN   NaN  NaN  4.00   NaN    NaN   \n",
       "3  NaN   NaN  NaN   NaN   0.2    0.5   \n",
       "4    2   NaN  NaN  0.64  0.35    1.2   \n",
       "\n",
       "                                             Caption  \\\n",
       "0          Chemical composition of primary material.   \n",
       "1          Chemical composition of primary material.   \n",
       "2          Chemical composition of primary material.   \n",
       "3  Oxide composition and chemical properties of H...   \n",
       "4  Oxide composition and chemical properties of H...   \n",
       "\n",
       "                                 DOI  \\\n",
       "0  10.1016/j.conbuildmat.2009.10.010   \n",
       "1  10.1016/j.conbuildmat.2009.10.010   \n",
       "2  10.1016/j.conbuildmat.2009.10.010   \n",
       "3  10.1016/j.conbuildmat.2010.01.022   \n",
       "4  10.1016/j.conbuildmat.2010.01.022   \n",
       "\n",
       "                                          Descriptor  \n",
       "0   The Zeolitic rock from Sakhaptinskoe deposit ...  \n",
       "1   Ash microspheres are spherical particles prim...  \n",
       "2   Vermiculite is a mineral composed primarily o...  \n",
       "3   The material named 'HAC' contains approximate...  \n",
       "4   The material named 'OPC' has an oxide composi...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the data from CSV files\n",
    "materials_df = pd.read_csv('final_compositions.csv', encoding='cp1252')\n",
    "\n",
    "\n",
    "materials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0a2d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b136f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 8016/14462 [40:24<23:31,  4.57it/s]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 14462/14462 [1:10:38<00:00,  3.41it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (index, row) in enumerate(tqdm(materials_df.iterrows(), total=materials_df.shape[0])):\n",
    "    RR =0\n",
    "    material_name = row['Material Name']\n",
    "    doi = row['DOI']\n",
    "    caption = row['Caption']\n",
    "    descriptor = row['Descriptor']\n",
    "    try: \n",
    "        \n",
    "        Prompt = f\"\"\"How do you categorize the material called '{material_name}' based on the following information: \n",
    "        Caption of the table that described the chemical composition of this material: {caption}\n",
    "        Descriptor from another language model: {descriptor}\n",
    "\n",
    "        Category of the material '{material_name}': \"\"\"\n",
    "\n",
    "        # Check if this caption and DOI already exist in the existing DataFrame\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-3.5-turbo-1106:personal::8kzjZwlt\",messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant trained to classify the materials based on the description provided and your own knowledge about materials.\"},\n",
    "        {\"role\": \"user\", \"content\": Prompt}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=100,\n",
    "        top_p=1,)\n",
    "\n",
    "        RR=response.choices[0].message.content\n",
    "\n",
    "        # Check if it's time to save the responses\n",
    "        if (i + 1) % 100 == 0:\n",
    "            save_responses(responses)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    RR=response.choices[0].message.content\n",
    "    responses.append((material_name, caption, doi,descriptor, RR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ff78302",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_responses(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e68721c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('all_materials_extracted_fgpt.csv', encoding='unicode_escape')\n",
    "oxide_columns = ['SiO2', 'Al2O3', 'Fe2O3', 'CaO', 'MgO', 'SO3', 'TiO2', 'MnO', 'K2O', 'Na2O', 'LOI']\n",
    "\n",
    "        \n",
    "# Function to sum oxide values and handle errors\n",
    "def sum_oxides(row):\n",
    "    try:\n",
    "        return row[oxide_columns].astype(float).sum()\n",
    "    except ValueError:\n",
    "        return 'error'\n",
    "\n",
    "# Apply the function to each row\n",
    "data['Sum'] = data.apply(sum_oxides, axis=1)\n",
    "\n",
    "# Identify rows with errors\n",
    "rows_with_errors = data['Sum'] == 'error'\n",
    "\n",
    "# Extract rows for manual check\n",
    "data_non_numeric = data[rows_with_errors]\n",
    "\n",
    "# Save these rows to a new file for manual checking\n",
    "data_non_numeric.to_excel('manual_check.xlsx', index=False)\n",
    "\n",
    "# Optionally, remove these rows from the original DataFrame\n",
    "data = data[~rows_with_errors]\n",
    "data.to_csv('Final_ext_compositions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6243b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soroush1",
   "language": "python",
   "name": "soroush1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
